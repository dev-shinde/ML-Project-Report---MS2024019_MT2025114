{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365eff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the training and test data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# =============================================\n",
    "# Separate features and target\n",
    "# =============================================\n",
    "X_train = train.drop(['id', 'WeightCategory'], axis=1)\n",
    "y_train = train['WeightCategory']\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)  # Only features, no target\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test  = pd.get_dummies(X_test,  drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "# Base model\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Focused Grid Search Space based on your top performers\n",
    "param_grid = {\n",
    "    'n_estimators':  [347,349],\n",
    "    'learning_rate': np.linspace(0.17, 0.2, 9),\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [ 4.4 ],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'gamma': [0.49,  0.52],\n",
    "    'reg_alpha':  [ 0.72, 0.69 ],\n",
    "    'reg_lambda': [2.97,3.02],\n",
    "}\n",
    "print(f\"Total combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_s, y_train_enc)\n",
    "\n",
    "print(\"✅ Best parameters:\", grid_search.best_params_)\n",
    "print(\"✅ Best CV Accuracy:\", grid_search.best_score_ * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21961532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Extract top 10 parameter sets ======\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Sort by mean_test_score descending and take top 10\n",
    "top10 = results_df.sort_values('mean_test_score', ascending=False).head(10)\n",
    "\n",
    "print(f\"\\nTop 10 parameter sets:\")\n",
    "for idx, (_, row) in enumerate(top10.iterrows(), 1):\n",
    "    print(f\"{idx}: {row['mean_test_score']:.4f} => params={row['params']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Loop through top 10 and train/predict & save CSVs ======\n",
    "for i, (_, row) in enumerate(top10.iterrows(), 1):\n",
    "    params_i = row['params']\n",
    "    print(f\"\\nTraining model #{i} with score {row['mean_test_score']:.4f}\")\n",
    "    print(f\"Params: {params_i}\")\n",
    "    \n",
    "    model_i = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist',\n",
    "        **params_i\n",
    "    )\n",
    "    \n",
    "    # Train on full training data\n",
    "    model_i.fit(X_train_s, y_train_enc)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred_i = model_i.predict(X_test_s)\n",
    "    y_pred_labels_i = le.inverse_transform(y_pred_i)\n",
    "    \n",
    "    # Create submission file\n",
    "    submission_i = pd.DataFrame({'id': test['id'], 'WeightCategory': y_pred_labels_i})\n",
    "    filename = f\"model{i}_score_{row['mean_test_score']:.4f}.csv\"\n",
    "    submission_i.to_csv(filename, index=False)\n",
    "    print(f\"✅ Saved {filename}\")\n",
    "\n",
    "print(f\"\\nAll done. Generated 10 submission files: submission_top10_model1.csv … submission_top10_model10.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
