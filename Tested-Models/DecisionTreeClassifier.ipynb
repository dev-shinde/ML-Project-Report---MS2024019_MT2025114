{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Classification using Decision Tree\n",
    "\n",
    "This notebook trains and evaluates a Decision Tree Classifier model on the obesity dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(f\"Missing values per column:\\n{missing_values[missing_values > 0]}\")\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    print(f\"Categorical columns: {categorical_cols.tolist()}\")\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "    \n",
    "    X = df.drop(['id', 'WeightCategory'], axis=1)\n",
    "    y = df['WeightCategory']\n",
    "    \n",
    "    print(\"\\nTarget class distribution:\")\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    le_target = LabelEncoder()\n",
    "    y_encoded = le_target.fit_transform(y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.25, random_state=42)\n",
    "    \n",
    "    return X, X_scaled, y, y_encoded, X_train, X_test, y_train, y_test, categorical_cols, encoders, le_target, scaler\n",
    "\n",
    "file_path = \"train.csv\"\n",
    "\n",
    "X, X_scaled, y, y_encoded, X_train, X_test, y_train, y_test, categorical_cols, encoders, le_target, scaler = load_and_preprocess_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Results Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"decision_tree_results\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "print(f\"Results will be saved to '{results_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find Optimal Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = list(range(1, 21))\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tree.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy.append(train_acc)\n",
    "    \n",
    "    y_test_pred = tree.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_accuracy.append(test_acc)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_accuracy, label='Training Accuracy', marker='o')\n",
    "plt.plot(max_depths, test_accuracy, label='Testing Accuracy', marker='o')\n",
    "plt.xlabel('Maximum Tree Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Maximum Tree Depth')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(max_depths)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/tree_depth_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "optimal_depth = max_depths[test_accuracy.index(max(test_accuracy))]\n",
    "print(f\"Optimal tree depth: {optimal_depth} with testing accuracy: {max(test_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Decision Tree with Optimal Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "model = DecisionTreeClassifier(max_depth=optimal_depth, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "training_time = time() - start_time\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Decision Tree Classifier')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{results_dir}/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importances_df = importances_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importances_df['Feature'], importances_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Decision Tree Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/feature_importances.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Features by Importance:\")\n",
    "print(importances_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Decision Tree (simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "simple_tree.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(simple_tree, \n",
    "          feature_names=feature_names,\n",
    "          class_names=[str(c) for c in simple_tree.classes_],\n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          fontsize=10)\n",
    "plt.title('Simplified Decision Tree (max_depth=3)')\n",
    "plt.savefig(f\"{results_dir}/simplified_tree.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv(f\"{results_dir}/classification_report.csv\")\n",
    "print(f\"Classification report saved to {results_dir}/classification_report.csv\")\n",
    "\n",
    "importances_df.to_csv(f\"{results_dir}/feature_importances.csv\", index=False)\n",
    "print(f\"Feature importances saved to {results_dir}/feature_importances.csv\")\n",
    "\n",
    "results = {\n",
    "    'Model': 'DecisionTreeClassifier',\n",
    "    'Training Accuracy': train_accuracy,\n",
    "    'Testing Accuracy': test_accuracy,\n",
    "    'Training Time (s)': training_time,\n",
    "    'Optimal Depth': optimal_depth\n",
    "}\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv(f\"{results_dir}/results_summary.csv\", index=False)\n",
    "print(f\"Results summary saved to {results_dir}/results_summary.csv\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Process Test Data and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test_encoded = test.copy().drop(columns=[\"id\"])\n",
    "\n",
    "for col in test_encoded.select_dtypes(include=['object']).columns:\n",
    "    if col in encoders:\n",
    "        test_encoded[col] = encoders[col].transform(test_encoded[col].astype(str))\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        test_encoded[col] = le.fit_transform(test_encoded[col].astype(str))\n",
    "\n",
    "test_scaled = scaler.transform(test_encoded)\n",
    "test_preds = model.predict(test_scaled)\n",
    "test_preds_labels = le_target.inverse_transform(test_preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"WeightCategory\": test_preds_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_decision_tree.csv\", index=False)\n",
    "print(\"\\nsubmission_decision_tree.csv is ready for Kaggle!\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}