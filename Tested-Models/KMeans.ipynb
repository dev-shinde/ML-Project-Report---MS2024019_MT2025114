{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Classification using K-Means Clustering\n",
    "\n",
    "This notebook trains and evaluates a K-Means Clustering model on the obesity dataset. Note that K-Means is an unsupervised learning algorithm, so we'll need to map cluster labels to actual classes for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(f\"Missing values per column:\\n{missing_values[missing_values > 0]}\")\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    print(f\"Categorical columns: {categorical_cols.tolist()}\")\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "    \n",
    "    X = df.drop(['id', 'WeightCategory'], axis=1)\n",
    "    y = df['WeightCategory']\n",
    "    \n",
    "    print(\"\\nTarget class distribution:\")\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    le_target = LabelEncoder()\n",
    "    y_encoded = le_target.fit_transform(y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.25, random_state=42)\n",
    "    \n",
    "    n_classes = len(np.unique(y_encoded))\n",
    "    print(f\"\\nNumber of unique classes: {n_classes}\")\n",
    "    \n",
    "    return X, X_scaled, y, y_encoded, X_train, X_test, y_train, y_test, categorical_cols, encoders, le_target, scaler, n_classes\n",
    "\n",
    "file_path = \"train.csv\"\n",
    "\n",
    "X, X_scaled, y, y_encoded, X_train, X_test, y_train, y_test, categorical_cols, encoders, le_target, scaler, n_classes = load_and_preprocess_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Results Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"kmeans_results\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "print(f\"Results will be saved to '{results_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "k_range = range(1, 15)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, sse, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{results_dir}/elbow_method.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Based on our dataset, we'll use {n_classes} clusters as we have {n_classes} unique weight categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train K-Means Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "model = KMeans(n_clusters=n_classes, random_state=42)\n",
    "model.fit(X_train)\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cluster_to_label = {}\n",
    "for cluster in range(model.n_clusters):\n",
    "    mask = (train_predictions == cluster)\n",
    "    if np.any(mask):\n",
    "        counter = Counter(y_train[mask])\n",
    "        most_common = counter.most_common(1)\n",
    "        if most_common:\n",
    "            cluster_to_label[cluster] = most_common[0][0]\n",
    "        else:\n",
    "            cluster_to_label[cluster] = -1\n",
    "    else:\n",
    "        cluster_to_label[cluster] = -1\n",
    "\n",
    "print(\"Cluster to Label Mapping:\")\n",
    "for cluster, label in cluster_to_label.items():\n",
    "    print(f\"Cluster {cluster} â†’ Label {label}\")\n",
    "\n",
    "y_pred_mapped = np.array([cluster_to_label.get(label, -1) for label in y_pred])\n",
    "train_pred_mapped = np.array([cluster_to_label.get(label, -1) for label in train_predictions])\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_pred_mapped)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_mapped)\n",
    "training_time = time() - start_time\n",
    "\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_mapped, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_mapped)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - K-Means Clustering')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{results_dir}/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Clusters (2D Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_viz = PCA(n_components=2)\n",
    "X_train_2d = pca_viz.fit_transform(X_train)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.title('Actual Classes')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=train_predictions, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.title('K-Means Clusters')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/cluster_visualization.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv(f\"{results_dir}/classification_report.csv\")\n",
    "print(f\"Classification report saved to {results_dir}/classification_report.csv\")\n",
    "\n",
    "mapping_df = pd.DataFrame(list(cluster_to_label.items()), columns=['Cluster', 'Label'])\n",
    "mapping_df.to_csv(f\"{results_dir}/cluster_mapping.csv\", index=False)\n",
    "print(f\"Cluster mapping saved to {results_dir}/cluster_mapping.csv\")\n",
    "\n",
    "results = {\n",
    "    'Model': 'KMeans',\n",
    "    'Training Accuracy': train_accuracy,\n",
    "    'Testing Accuracy': test_accuracy,\n",
    "    'Training Time (s)': training_time,\n",
    "    'Number of Clusters': n_classes\n",
    "}\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv(f\"{results_dir}/results_summary.csv\", index=False)\n",
    "print(f\"Results summary saved to {results_dir}/results_summary.csv\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Process Test Data and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test_encoded = test.copy().drop(columns=[\"id\"])\n",
    "\n",
    "for col in test_encoded.select_dtypes(include=['object']).columns:\n",
    "    if col in encoders:\n",
    "        test_encoded[col] = encoders[col].transform(test_encoded[col].astype(str))\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        test_encoded[col] = le.fit_transform(test_encoded[col].astype(str))\n",
    "\n",
    "test_scaled = scaler.transform(test_encoded)\n",
    "test_preds_clusters = model.predict(test_scaled)\n",
    "test_preds = np.array([cluster_to_label.get(label, -1) for label in test_preds_clusters])\n",
    "test_preds_labels = le_target.inverse_transform(test_preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"WeightCategory\": test_preds_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_kmeans.csv\", index=False)\n",
    "print(\"\\nsubmission_kmeans.csv is ready for Kaggle!\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}